{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMS/C59SsH4YUphSIy6ivVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/hwr/blob/master/notebook-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1NNlFTNfIP",
        "colab_type": "text"
      },
      "source": [
        "# Simple HWR - TensorFlow\n",
        "Implementation of Gated Convolutional Recurrent Neural Network for Handwriting Recognition as recorded in [Bluche](http://ieeexplore.ieee.org/document/8270042/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEofDy6iNq2F",
        "colab_type": "code",
        "outputId": "4671a1ea-0ebd-4264-8fdf-abb2118ed886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxp4_ThN0OM",
        "colab_type": "code",
        "outputId": "203ffe22-e788-46e4-fb2a-3ba8adbd4fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjM6wL9vCY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/iam.zip\" \"/content\"\n",
        "!unzip -q iam.zip\n",
        "!rm iam.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTb_wcEW4SFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder():\n",
        "  # input => (tuple of strings)\n",
        "  def get_representation(words):\n",
        "    charlists = []\n",
        "    zeros = np.zeros(20)\n",
        "\n",
        "    if type(words) == str:\n",
        "      charlist = [ord(c) for c in words]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "      return np.array(charlists)\n",
        "\n",
        "    for word in words:\n",
        "      charlist = [ord(c) for c in word]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "    return np.array(charlists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt5fgIdznaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img, desired_size):\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "    # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "    # Solve by width\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  border_img = cv2.copyMakeBorder(\n",
        "      img,\n",
        "      top=border_top,\n",
        "      bottom=0,\n",
        "      left=0,\n",
        "      right=border_right,\n",
        "      borderType=cv2.BORDER_CONSTANT,\n",
        "      value=[255]\n",
        "  )\n",
        "\n",
        "  return border_img\n",
        "\n",
        "def tensor_image(path, desired_size):\n",
        "  img = Image.open(path + '.png')\n",
        "  img = resize(img, desired_size)\n",
        "  x = np.array(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def iam_generator(desired_size=(128, 32), path='/content/labels.csv'):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Iam dataset does not exist in ' + path)\n",
        "\n",
        "  df = pd.read_csv(path, sep='\\t', header=None, names=['word', 'seg', 'transcription'])\n",
        "  df = df.drop(['seg'], axis=1)\n",
        "  df = df.drop(df[df['transcription'] == '.'].index)\n",
        "  df = df.drop(df[df['transcription'] == '!'].index)\n",
        "  df = df.drop(df[df['transcription'] == ','].index)\n",
        "  df = df.drop(df[df['transcription'] == ';'].index)\n",
        "  df = df.drop(df[df['transcription'] == ':'].index)    \n",
        "  df = df.drop(df[df['transcription'] == ')'].index)\n",
        "  df = df.drop(df[df['transcription'] == '('].index)\n",
        "  df = df.reset_index()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'images/' + row['word'] + '.png'\n",
        "    img = Image.open(path)\n",
        "    img = resize_img(img, desired_size)\n",
        "    x = tf.expand_dims(tf.convert_to_tensor(np.array(img)), 2)\n",
        "    y = tf.convert_to_tensor(Encoder.get_representation(row['transcription']))\n",
        "\n",
        "    yield(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7naHe62AGW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(Model):\n",
        "  def __init__(self):\n",
        "    super(Recognizer, self).__init__()\n",
        "    \n",
        "    # Encoder\n",
        "    self.conv1 = L.Conv2D(8, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv2 = L.Conv2D(16, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv3 = L.Conv2D(32, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv4 = L.Conv2D(64, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv5 = L.Conv2D(128, 3, strides=1, padding='same', activation='tanh')\n",
        "\n",
        "    self.gate1 = L.Conv2D(16, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate2 = L.Conv2D(32, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate3 = L.Conv2D(64, 3, strides=1, padding='same', activation='sigmoid')\n",
        "\n",
        "    # MaxPool\n",
        "    self.mp = L.MaxPool2D((32, 1))\n",
        "\n",
        "    # Decoder\n",
        "    self.gru1 = L.Bidirectional(L.GRU(256, return_sequences=True))\n",
        "    self.fc1 = L.Dense(128)\n",
        "    self.gru2 = L.Bidirectional(L.GRU(256, return_sequences=True))\n",
        "    self.fc2 = L.Dense(16)\n",
        "\n",
        "  def call(self, x):\n",
        "    # Encoder\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(x)\n",
        "\n",
        "    g1 = self.gate1(out)\n",
        "    out = out * g1\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    \n",
        "    g2 = self.gate2(out)\n",
        "    out = out * g2\n",
        "\n",
        "    out = self.conv4(out)\n",
        "\n",
        "    g3 = self.gate3(out)\n",
        "    out = out * g3\n",
        "\n",
        "    out = self.conv5(out)\n",
        "\n",
        "    # Max Pooling across vertical dimension\n",
        "    out = self.mp(out)\n",
        "\n",
        "    # Decoder\n",
        "    out = tf.reshape(out, [-1, 128, 128])\n",
        "\n",
        "    out = self.gru1(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.gru2(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2zKBeJSFlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_lengths(tensors):\n",
        "  lengths = []\n",
        "\n",
        "  tensors = tf.reshape(tensors, (-1, 16))\n",
        "\n",
        "  print(tensors)\n",
        "\n",
        "  for tensor in tensors:\n",
        "    count = 0\n",
        "    for val in tensor:\n",
        "      if val != 0:\n",
        "        count += 1\n",
        "      else:\n",
        "        break\n",
        "    \n",
        "    lengths.append(count)\n",
        "\n",
        "  print('after for loop')\n",
        "\n",
        "  return lengths #tf.dtypes.cast(lengths, tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti4o1NDVwKs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "31bf78cf-2fd6-4b3e-a771-7804f23cecd0"
      },
      "source": [
        "tensors = tf.constant(np.array([[[65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[65, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]))\n",
        "print(tensors.shape)\n",
        "tf.constant(seq_lengths(tensors))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1, 16)\n",
            "tf.Tensor(\n",
            "[[65  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [65  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0]], shape=(2, 16), dtype=int64)\n",
            "after for loop\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 5], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0d6IYRdF4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = tf.constant(np.random.randn(5, 32, 128, 1))\n",
        "model = Recognizer()\n",
        "\n",
        "model(t).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAIwzQyJ_7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_size = images.shape[0]\n",
        "    input_lengths = tf.constant(np.full((batch_size,), 16))\n",
        "    label_lengths = seq_lengths(labels)\n",
        "    print('made it this far')\n",
        "    predictions = model(images)\n",
        "    loss = tf.nn.ctc_loss(labels, predictions, label_lengths, input_lengths, logits_time_major=False)\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmXI2FwZ9GX",
        "colab_type": "code",
        "outputId": "d2916dcb-248d-4cc7-8b7d-d997309b7dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  EPOCHS = 1\n",
        "  BATCH_SIZE = 250\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "      iam_generator,\n",
        "      (tf.int64, tf.int32),\n",
        "      (tf.TensorShape([None, None, 1]), tf.TensorShape([None, 16]))\n",
        "  )\n",
        "\n",
        "  train_dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  model = Recognizer()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for step, (images, labels) in enumerate(train_dataset):\n",
        "      train_step(images, labels)\n",
        "    \n",
        "    print('Epoch: {}, Loss: {}'.format(epoch, train_loss.result()))\n",
        "except:\n",
        "  __ITB__()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=int64...       [223],\n",
            "         [246],\n",
            "         [247]]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...8, 101,   0, ...,   0,   0,   0]]], dtype=int32)>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._call\u001b[0m \u001b[0;34m= <bound method Function._call of <tensorflow.python.eager.def_function.Function object at 0x7ff02efd96d8>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32, 1), dtype=int64, numpy=\n",
            "array([[[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[127],\n",
            "         [190],\n",
            "         [230],\n",
            "         ...,\n",
            "         [157],\n",
            "         [226],\n",
            "         [240]],\n",
            "\n",
            "        [[145],\n",
            "         [205],\n",
            "         [237],\n",
            "         ...,\n",
            "         [203],\n",
            "         [239],\n",
            "         [242]],\n",
            "\n",
            "        [[162],\n",
            "         [219],\n",
            "         [241],\n",
            "         ...,\n",
            "         [232],\n",
            "         [239],\n",
            "         [242]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[133],\n",
            "         [140],\n",
            "         [ 75],\n",
            "         ...,\n",
            "         [173],\n",
            "         [247],\n",
            "         [255]],\n",
            "\n",
            "        [[ 99],\n",
            "         [203],\n",
            "         [212],\n",
            "         ...,\n",
            "         [128],\n",
            "         [248],\n",
            "         [255]],\n",
            "\n",
            "        [[123],\n",
            "         [239],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [171],\n",
            "         [236],\n",
            "         [247]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [245],\n",
            "         [246],\n",
            "         [245]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [245],\n",
            "         [246],\n",
            "         [248]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[185],\n",
            "         [ 83],\n",
            "         [155],\n",
            "         ...,\n",
            "         [110],\n",
            "         [212],\n",
            "         [248]],\n",
            "\n",
            "        [[115],\n",
            "         [114],\n",
            "         [145],\n",
            "         ...,\n",
            "         [161],\n",
            "         [228],\n",
            "         [244]],\n",
            "\n",
            "        [[118],\n",
            "         [219],\n",
            "         [206],\n",
            "         ...,\n",
            "         [251],\n",
            "         [247],\n",
            "         [244]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[240],\n",
            "         [233],\n",
            "         [246],\n",
            "         ...,\n",
            "         [247],\n",
            "         [244],\n",
            "         [245]],\n",
            "\n",
            "        [[188],\n",
            "         [232],\n",
            "         [242],\n",
            "         ...,\n",
            "         [246],\n",
            "         [245],\n",
            "         [247]],\n",
            "\n",
            "        [[167],\n",
            "         [177],\n",
            "         [169],\n",
            "         ...,\n",
            "         [246],\n",
            "         [244],\n",
            "         [245]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[221],\n",
            "         [165],\n",
            "         [ 87],\n",
            "         ...,\n",
            "         [244],\n",
            "         [246],\n",
            "         [248]],\n",
            "\n",
            "        [[135],\n",
            "         [105],\n",
            "         [130],\n",
            "         ...,\n",
            "         [241],\n",
            "         [249],\n",
            "         [249]],\n",
            "\n",
            "        [[226],\n",
            "         [231],\n",
            "         [243],\n",
            "         ...,\n",
            "         [223],\n",
            "         [246],\n",
            "         [247]]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]], dtype=int32)>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=int64...       [223],\n",
            "         [246],\n",
            "         [247]]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...8, 101,   0, ...,   0,   0,   0]]], dtype=int32)>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself._stateless_fn\u001b[0m \u001b[0;34m= None\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32, 1), dtype=int64, numpy=\n",
            "array([[[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[127],\n",
            "         [190],\n",
            "         [230],\n",
            "         ...,\n",
            "         [157],\n",
            "         [226],\n",
            "         [240]],\n",
            "\n",
            "        [[145],\n",
            "         [205],\n",
            "         [237],\n",
            "         ...,\n",
            "         [203],\n",
            "         [239],\n",
            "         [242]],\n",
            "\n",
            "        [[162],\n",
            "         [219],\n",
            "         [241],\n",
            "         ...,\n",
            "         [232],\n",
            "         [239],\n",
            "         [242]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[133],\n",
            "         [140],\n",
            "         [ 75],\n",
            "         ...,\n",
            "         [173],\n",
            "         [247],\n",
            "         [255]],\n",
            "\n",
            "        [[ 99],\n",
            "         [203],\n",
            "         [212],\n",
            "         ...,\n",
            "         [128],\n",
            "         [248],\n",
            "         [255]],\n",
            "\n",
            "        [[123],\n",
            "         [239],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [171],\n",
            "         [236],\n",
            "         [247]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [245],\n",
            "         [246],\n",
            "         [245]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [245],\n",
            "         [246],\n",
            "         [248]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[185],\n",
            "         [ 83],\n",
            "         [155],\n",
            "         ...,\n",
            "         [110],\n",
            "         [212],\n",
            "         [248]],\n",
            "\n",
            "        [[115],\n",
            "         [114],\n",
            "         [145],\n",
            "         ...,\n",
            "         [161],\n",
            "         [228],\n",
            "         [244]],\n",
            "\n",
            "        [[118],\n",
            "         [219],\n",
            "         [206],\n",
            "         ...,\n",
            "         [251],\n",
            "         [247],\n",
            "         [244]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[240],\n",
            "         [233],\n",
            "         [246],\n",
            "         ...,\n",
            "         [247],\n",
            "         [244],\n",
            "         [245]],\n",
            "\n",
            "        [[188],\n",
            "         [232],\n",
            "         [242],\n",
            "         ...,\n",
            "         [246],\n",
            "         [245],\n",
            "         [247]],\n",
            "\n",
            "        [[167],\n",
            "         [177],\n",
            "         [169],\n",
            "         ...,\n",
            "         [246],\n",
            "         [244],\n",
            "         [245]]],\n",
            "\n",
            "\n",
            "       [[[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        [[255],\n",
            "         [255],\n",
            "         [255],\n",
            "         ...,\n",
            "         [255],\n",
            "         [255],\n",
            "         [255]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[221],\n",
            "         [165],\n",
            "         [ 87],\n",
            "         ...,\n",
            "         [244],\n",
            "         [246],\n",
            "         [248]],\n",
            "\n",
            "        [[135],\n",
            "         [105],\n",
            "         [130],\n",
            "         ...,\n",
            "         [241],\n",
            "         [249],\n",
            "         [249]],\n",
            "\n",
            "        [[226],\n",
            "         [231],\n",
            "         [243],\n",
            "         ...,\n",
            "         [223],\n",
            "         [246],\n",
            "         [247]]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]], dtype=int32)>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLQgNk4Td_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = tf.convert_to_tensor(tf.constant([[1, 2, 3]]))\n",
        "tf.reshape(t, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSA1f8pLq6D",
        "colab_type": "code",
        "outputId": "e9ceec9d-ba13-47af-9faf-fdccb26ca2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    iam_generator,\n",
        "    (tf.int64, tf.int64),\n",
        "    (tf.TensorShape([None, None, 1]), tf.TensorShape([None, 16]))\n",
        ")\n",
        "train_dataset = dataset.batch(BATCH_SIZE)\n",
        "for step, (x, y) in enumerate(train_dataset):\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "\n",
        "  break"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 128, 32, 1)\n",
            "(100, 1, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}