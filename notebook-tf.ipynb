{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiqKhbsPyBTlQW4JdbXrlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/hwr/blob/master/notebook-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1NNlFTNfIP",
        "colab_type": "text"
      },
      "source": [
        "# Simple HWR - TensorFlow\n",
        "Implementation of Gated Convolutional Recurrent Neural Network for Handwriting Recognition as recorded in [Bluche](http://ieeexplore.ieee.org/document/8270042/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEofDy6iNq2F",
        "colab_type": "code",
        "outputId": "22fd655c-bb1c-4895-b6e5-46a7551038e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxp4_ThN0OM",
        "colab_type": "code",
        "outputId": "e8ee3a1d-828d-45c3-924c-016ca601d247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjM6wL9vCY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "14222c4d-c4b1-4e88-8c04-7aeccc12b2e5"
      },
      "source": [
        "!cp \"drive/My Drive/datasets/iam.zip\" \"/content\"\n",
        "!unzip -q iam.zip\n",
        "!rm iam.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning [iam.zip]:  76 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "error [iam.zip]:  reported length of central directory is\n",
            "  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n",
            "  zipfile?).  Compensating...\n",
            "error:  expected central file header signature not found (file #95170).\n",
            "  (please check that you have transferred or created the zipfile in the\n",
            "  appropriate BINARY mode and that you have compiled UnZip properly)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTb_wcEW4SFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder():\n",
        "  # input => (tuple of strings)\n",
        "  def get_representation(words):\n",
        "    charlists = []\n",
        "    zeros = np.zeros(20)\n",
        "\n",
        "    if type(words) == str:\n",
        "      charlist = [ord(c) for c in words]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "      return np.array(charlists)\n",
        "\n",
        "    for word in words:\n",
        "      charlist = [ord(c) for c in word]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "    return np.array(charlists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt5fgIdznaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img, desired_size):\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "    # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "    # Solve by width\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  border_img = cv2.copyMakeBorder(\n",
        "      img,\n",
        "      top=border_top,\n",
        "      bottom=0,\n",
        "      left=0,\n",
        "      right=border_right,\n",
        "      borderType=cv2.BORDER_CONSTANT,\n",
        "      value=[255]\n",
        "  )\n",
        "\n",
        "  return border_img\n",
        "\n",
        "def tensor_image(path, desired_size):\n",
        "  img = Image.open(path + '.png')\n",
        "  img = resize(img, desired_size)\n",
        "  x = np.array(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def iam_generator(desired_size=(128, 32), path='/content/labels.csv'):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Iam dataset does not exist in ' + path)\n",
        "\n",
        "  df = pd.read_csv(path, sep='\\t', header=None, names=['word', 'seg', 'transcription'])\n",
        "  df = df.drop(['seg'], axis=1)\n",
        "  df = df.drop(df[df['transcription'] == '.'].index)\n",
        "  df = df.drop(df[df['transcription'] == '!'].index)\n",
        "  df = df.drop(df[df['transcription'] == ','].index)\n",
        "  df = df.drop(df[df['transcription'] == ';'].index)\n",
        "  df = df.drop(df[df['transcription'] == ':'].index)    \n",
        "  df = df.drop(df[df['transcription'] == ')'].index)\n",
        "  df = df.drop(df[df['transcription'] == '('].index)\n",
        "  df = df.reset_index()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'images/' + row['word'] + '.png'\n",
        "    img = Image.open(path)\n",
        "    img = resize_img(img, desired_size)\n",
        "    x = tf.expand_dims(tf.convert_to_tensor(np.array(img), dtype=tf.float32), 2)\n",
        "    y = tf.convert_to_tensor(Encoder.get_representation(row['transcription']), dtype=tf.int32)\n",
        "\n",
        "    yield(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7naHe62AGW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(Model):\n",
        "  def __init__(self):\n",
        "    super(Recognizer, self).__init__()\n",
        "    \n",
        "    # Encoder\n",
        "    self.conv1 = L.Conv2D(8, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv2 = L.Conv2D(16, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv3 = L.Conv2D(32, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv4 = L.Conv2D(64, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv5 = L.Conv2D(128, 3, strides=1, padding='same', activation='tanh')\n",
        "\n",
        "    self.gate1 = L.Conv2D(16, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate2 = L.Conv2D(32, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate3 = L.Conv2D(64, 3, strides=1, padding='same', activation='sigmoid')\n",
        "\n",
        "    # MaxPool\n",
        "    self.mp = L.MaxPool2D((32, 1))\n",
        "\n",
        "    # Decoder\n",
        "    self.gru1 = L.Bidirectional(L.GRU(256, return_sequences=True))\n",
        "    self.fc1 = L.Dense(128)\n",
        "    self.gru2 = L.Bidirectional(L.GRU(256, return_sequences=True))\n",
        "    self.fc2 = L.Dense(16)\n",
        "    self.permute = L.Permute((2, 1))\n",
        "\n",
        "  def call(self, x):\n",
        "    # Encoder\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(x)\n",
        "\n",
        "    g1 = self.gate1(out)\n",
        "    out = out * g1\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    \n",
        "    g2 = self.gate2(out)\n",
        "    out = out * g2\n",
        "\n",
        "    out = self.conv4(out)\n",
        "\n",
        "    g3 = self.gate3(out)\n",
        "    out = out * g3\n",
        "\n",
        "    out = self.conv5(out)\n",
        "\n",
        "    # Max Pooling across vertical dimension\n",
        "    out = self.mp(out)\n",
        "\n",
        "    # Decoder\n",
        "    out = tf.reshape(out, [-1, 128, 128])\n",
        "\n",
        "    out = self.gru1(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.gru2(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.permute(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAIwzQyJ_7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_size = images.shape[0]\n",
        "    input_lengths = tf.constant(np.full((batch_size,), 16))\n",
        "    label_lengths = tf.squeeze(tf.math.count_nonzero(labels, axis=2))\n",
        "    predictions = model(images)\n",
        "    labels = tf.squeeze(labels, axis=1)\n",
        "\n",
        "    loss = tf.nn.ctc_loss(labels, predictions, label_lengths, input_lengths, logits_time_major=False,)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcUEAQHoqPuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39776cb5-ef02-4a5e-a768-6bac53adaaa8"
      },
      "source": [
        "tf.nn.softmax(tf.constant([-5.1231, -2.32342]))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.05734148, 0.94265854], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmXI2FwZ9GX",
        "colab_type": "code",
        "outputId": "50b2dd6f-d2f5-4433-de6c-94d3760d6717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  EPOCHS = 1\n",
        "  BATCH_SIZE = 250\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "      iam_generator,\n",
        "      (tf.float32, tf.int32),\n",
        "      (tf.TensorShape([None, None, 1]), tf.TensorShape([None, 16]))\n",
        "  )\n",
        "  train_dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  model = Recognizer()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for images, labels in train_dataset:\n",
        "      train_step(images, labels)\n",
        "      print('Epoch: {}, Loss: {}'.format(epoch, train_loss.result()))\n",
        "      \n",
        "except:\n",
        "  __ITB__()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['recognizer_39/conv2d_312/kernel:0', 'recognizer_39/conv2d_312/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['recognizer_39/conv2d_312/kernel:0', 'recognizer_39/conv2d_312/bias:0'] when minimizing the loss.\n",
            "Epoch: 0, Loss: 66.80127716064453\n",
            "Epoch: 0, Loss: 65.98078918457031\n",
            "Epoch: 0, Loss: 65.01065826416016\n",
            "Epoch: 0, Loss: 62.84225845336914\n",
            "Epoch: 0, Loss: 59.46714401245117\n",
            "Epoch: 0, Loss: 55.66038131713867\n",
            "Epoch: 0, Loss: 51.98318099975586\n",
            "Epoch: 0, Loss: 49.18561553955078\n",
            "Epoch: 0, Loss: 46.48262023925781\n",
            "Epoch: 0, Loss: 44.731666564941406\n",
            "Epoch: 0, Loss: 42.81177520751953\n",
            "Epoch: 0, Loss: 41.11843490600586\n",
            "Epoch: 0, Loss: 39.54366683959961\n",
            "Epoch: 0, Loss: 38.109642028808594\n",
            "Epoch: 0, Loss: 37.044803619384766\n",
            "Epoch: 0, Loss: 36.07862854003906\n",
            "Epoch: 0, Loss: 35.237876892089844\n",
            "Epoch: 0, Loss: 34.39948272705078\n",
            "Epoch: 0, Loss: 33.644737243652344\n",
            "Epoch: 0, Loss: 32.93911361694336\n",
            "Epoch: 0, Loss: 32.421871185302734\n",
            "Epoch: 0, Loss: 31.873327255249023\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._call\u001b[0m \u001b[0;34m= <bound method Function._call of <tensorflow.python.eager.def_function.Function object at 0x7f5328dc1940>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32, 1), dtype=float32, numpy=\n",
            "array([[[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[172.],\n",
            "         [125.],\n",
            "         [ 97.],\n",
            "         ...,\n",
            "         [249.],\n",
            "         [245.],\n",
            "         [246.]],\n",
            "\n",
            "        [[166.],\n",
            "         [168.],\n",
            "         [210.],\n",
            "         ...,\n",
            "         [190.],\n",
            "         [230.],\n",
            "         [248.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [195.],\n",
            "         [247.],\n",
            "         [249.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [255.],\n",
            "         [224.],\n",
            "         ...,\n",
            "         [252.],\n",
            "         [247.],\n",
            "         [249.]],\n",
            "\n",
            "        [[253.],\n",
            "         [192.],\n",
            "         [134.],\n",
            "         ...,\n",
            "         [253.],\n",
            "         [253.],\n",
            "         [253.]],\n",
            "\n",
            "        [[144.],\n",
            "         [169.],\n",
            "         [239.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [249.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [250.],\n",
            "         [247.],\n",
            "         [248.]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [250.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[254.],\n",
            "         [173.],\n",
            "         [ 70.],\n",
            "         ...,\n",
            "         [206.],\n",
            "         [235.],\n",
            "         [251.]],\n",
            "\n",
            "        [[245.],\n",
            "         [115.],\n",
            "         [103.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[240.],\n",
            "         [128.],\n",
            "         [172.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[198.],\n",
            "         [180.],\n",
            "         [252.],\n",
            "         ...,\n",
            "         [200.],\n",
            "         [206.],\n",
            "         [227.]],\n",
            "\n",
            "        [[216.],\n",
            "         [186.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[210.],\n",
            "         [196.],\n",
            "         [254.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[105, 100, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[102, 111, 114, ...,   0,   0,   0]]], dtype=int32)>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself._stateless_fn\u001b[0m \u001b[0;34m= <tensorflow.python.eager.function.Function object at 0x7f5328ef1978>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32, 1), dtype=float32, numpy=\n",
            "array([[[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[172.],\n",
            "         [125.],\n",
            "         [ 97.],\n",
            "         ...,\n",
            "         [249.],\n",
            "         [245.],\n",
            "         [246.]],\n",
            "\n",
            "        [[166.],\n",
            "         [168.],\n",
            "         [210.],\n",
            "         ...,\n",
            "         [190.],\n",
            "         [230.],\n",
            "         [248.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [195.],\n",
            "         [247.],\n",
            "         [249.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [255.],\n",
            "         [224.],\n",
            "         ...,\n",
            "         [252.],\n",
            "         [247.],\n",
            "         [249.]],\n",
            "\n",
            "        [[253.],\n",
            "         [192.],\n",
            "         [134.],\n",
            "         ...,\n",
            "         [253.],\n",
            "         [253.],\n",
            "         [253.]],\n",
            "\n",
            "        [[144.],\n",
            "         [169.],\n",
            "         [239.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [249.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [250.],\n",
            "         [247.],\n",
            "         [248.]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [250.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[254.],\n",
            "         [173.],\n",
            "         [ 70.],\n",
            "         ...,\n",
            "         [206.],\n",
            "         [235.],\n",
            "         [251.]],\n",
            "\n",
            "        [[245.],\n",
            "         [115.],\n",
            "         [103.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[240.],\n",
            "         [128.],\n",
            "         [172.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[198.],\n",
            "         [180.],\n",
            "         [252.],\n",
            "         ...,\n",
            "         [200.],\n",
            "         [206.],\n",
            "         [227.]],\n",
            "\n",
            "        [[216.],\n",
            "         [186.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[210.],\n",
            "         [196.],\n",
            "         [254.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[105, 100, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[102, 111, 114, ...,   0,   0,   0]]], dtype=int32)>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<tensorflow.python.eager.function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mgraph_function._filtered_call\u001b[0m \u001b[0;34m= <bound method ConcreteFunction._filtered_call of <tensorflow.python.eager.function.ConcreteFunction object at 0x7f53299e1e80>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32, 1), dtype=float32, numpy=\n",
            "array([[[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[172.],\n",
            "         [125.],\n",
            "         [ 97.],\n",
            "         ...,\n",
            "         [249.],\n",
            "         [245.],\n",
            "         [246.]],\n",
            "\n",
            "        [[166.],\n",
            "         [168.],\n",
            "         [210.],\n",
            "         ...,\n",
            "         [190.],\n",
            "         [230.],\n",
            "         [248.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [195.],\n",
            "         [247.],\n",
            "         [249.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [255.],\n",
            "         [224.],\n",
            "         ...,\n",
            "         [252.],\n",
            "         [247.],\n",
            "         [249.]],\n",
            "\n",
            "        [[253.],\n",
            "         [192.],\n",
            "         [134.],\n",
            "         ...,\n",
            "         [253.],\n",
            "         [253.],\n",
            "         [253.]],\n",
            "\n",
            "        [[144.],\n",
            "         [169.],\n",
            "         [239.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [249.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [250.],\n",
            "         [247.],\n",
            "         [248.]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [250.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[254.],\n",
            "         [173.],\n",
            "         [ 70.],\n",
            "         ...,\n",
            "         [206.],\n",
            "         [235.],\n",
            "         [251.]],\n",
            "\n",
            "        [[245.],\n",
            "         [115.],\n",
            "         [103.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[240.],\n",
            "         [128.],\n",
            "         [172.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[198.],\n",
            "         [180.],\n",
            "         [252.],\n",
            "         ...,\n",
            "         [200.],\n",
            "         [206.],\n",
            "         [227.]],\n",
            "\n",
            "        [[216.],\n",
            "         [186.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[210.],\n",
            "         [196.],\n",
            "         [254.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[105, 100, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[102, 111, 114, ...,   0,   0,   0]]], dtype=int32)>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self=<tensorflow.python.eager.function.ConcreteFunction object>, args=(<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>), kwargs={})\u001b[0m\n",
            "\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n",
            "\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n",
            "\u001b[0m        \u001b[0;36mself.captured_inputs\u001b[0m \u001b[0;34m= [<tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>]\u001b[0m\n",
            "\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self=<tensorflow.python.eager.function.ConcreteFunction object>, args=[<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, ...], captured_inputs=[<tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, ...], cancellation_manager=None)\u001b[0m\n",
            "\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n",
            "\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n",
            "\u001b[0m        \u001b[0;36mctx\u001b[0m \u001b[0;34m= <tensorflow.python.eager.context.Context object at 0x7f571403deb8>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= [<tf.Tensor: shape=(250, 128, 32, 1), dtype=float32, numpy=\n",
            "array([[[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[172.],\n",
            "         [125.],\n",
            "         [ 97.],\n",
            "         ...,\n",
            "         [249.],\n",
            "         [245.],\n",
            "         [246.]],\n",
            "\n",
            "        [[166.],\n",
            "         [168.],\n",
            "         [210.],\n",
            "         ...,\n",
            "         [190.],\n",
            "         [230.],\n",
            "         [248.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [195.],\n",
            "         [247.],\n",
            "         [249.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [255.],\n",
            "         [224.],\n",
            "         ...,\n",
            "         [252.],\n",
            "         [247.],\n",
            "         [249.]],\n",
            "\n",
            "        [[253.],\n",
            "         [192.],\n",
            "         [134.],\n",
            "         ...,\n",
            "         [253.],\n",
            "         [253.],\n",
            "         [253.]],\n",
            "\n",
            "        [[144.],\n",
            "         [169.],\n",
            "         [239.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [249.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [248.],\n",
            "         [247.],\n",
            "         [246.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [250.],\n",
            "         [247.],\n",
            "         [248.]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [250.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]],\n",
            "\n",
            "        [[251.],\n",
            "         [251.],\n",
            "         [251.],\n",
            "         ...,\n",
            "         [251.],\n",
            "         [251.],\n",
            "         [251.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[254.],\n",
            "         [173.],\n",
            "         [ 70.],\n",
            "         ...,\n",
            "         [206.],\n",
            "         [235.],\n",
            "         [251.]],\n",
            "\n",
            "        [[245.],\n",
            "         [115.],\n",
            "         [103.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[240.],\n",
            "         [128.],\n",
            "         [172.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]],\n",
            "\n",
            "\n",
            "       [[[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[255.],\n",
            "         [255.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[198.],\n",
            "         [180.],\n",
            "         [252.],\n",
            "         ...,\n",
            "         [200.],\n",
            "         [206.],\n",
            "         [227.]],\n",
            "\n",
            "        [[216.],\n",
            "         [186.],\n",
            "         [255.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]],\n",
            "\n",
            "        [[210.],\n",
            "         [196.],\n",
            "         [254.],\n",
            "         ...,\n",
            "         [255.],\n",
            "         [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, numpy=\n",
            "array([[[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[105, 100, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111, 102,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 104, 101, ...,   0,   0,   0]],\n",
            "\n",
            "       [[102, 111, 114, ...,   0,   0,   0]]], dtype=int32)>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>]\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mcancellation_manager\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self=<tensorflow.python.eager.function._EagerDefinedFunction object>, ctx=<tensorflow.python.eager.context.Context object>, args=[<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, ...], cancellation_manager=None)\u001b[0m\n",
            "\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n",
            "\u001b[0m        \u001b[0;36mctx\u001b[0m \u001b[0;34m= <tensorflow.python.eager.context.Context object at 0x7f571403deb8>\u001b[0m\n",
            "\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name='__inference_train_step_1018924', num_outputs=0, inputs=[<tf.Tensor: shape=(250, 128, 32, 1), dtype=float...      [255.],\n",
            "         [255.]]]], dtype=float32)>, <tf.Tensor: shape=(250, 1, 16), dtype=int32, num...2, 111, 114, ...,   0,   0,   0]]], dtype=int32)>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, ...], attrs=('executor_type', '', 'config_proto', b'\\n\\x07\\n\\x03GPU\\x10\\x01\\n\\x07\\n\\x03CPU\\x10\\x012\\x05*\\x010J\\x008\\x01'), ctx=<tensorflow.python.eager.context.Context object>, name=None)\u001b[0m\n",
            "\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n",
            "\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n",
            "\u001b[0m        \u001b[0;36mnum_outputs\u001b[0m \u001b[0;34m= 0\u001b[0m\n",
            "\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cisNgjQEaWNZ",
        "colab_type": "text"
      },
      "source": [
        "### CTC-Loss Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq63mlByTlr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5bb41d0d-c09d-4c0a-d068-9bfda6b0e93e"
      },
      "source": [
        "labels = tf.constant(np.random.randint(low=0, high=128, size=(1, 16)))\n",
        "preds = tf.constant(np.random.randn(1, 16, 128), dtype=tf.float32)\n",
        "llengths = tf.constant(np.random.randint(low=0, high=16, size=(1)))\n",
        "ilengths = tf.constant(np.full((1,), 16))\n",
        "\n",
        "print('labels: ', labels.shape)\n",
        "print(labels)\n",
        "print('preds: ', preds.shape)\n",
        "print(preds)\n",
        "print('input lengths: ', ilengths.shape)\n",
        "print(ilengths)\n",
        "print('label lengths: ', llengths.shape)\n",
        "print(llengths)\n",
        "\n",
        "tf.reduce_mean(tf.nn.ctc_loss(labels, preds, llengths, ilengths, logits_time_major=False, blank_index=0))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels:  (1, 16)\n",
            "tf.Tensor([[ 27  49  61  99  80  61  47  25  19  35  25  43 107  89 104  16]], shape=(1, 16), dtype=int64)\n",
            "preds:  (1, 16, 128)\n",
            "tf.Tensor(\n",
            "[[[ 1.3211424   0.36390853 -0.5032348  ...  0.5346142   0.15908684\n",
            "    0.6808094 ]\n",
            "  [ 0.10130436 -1.150955   -0.03122388 ...  0.3131712   0.22086355\n",
            "   -0.67402965]\n",
            "  [ 0.47346625 -1.4858168  -1.1933379  ... -1.0516319  -1.0400614\n",
            "    0.26930356]\n",
            "  ...\n",
            "  [-0.4674597   1.482517   -1.3243313  ...  0.05548872  0.812202\n",
            "   -2.0924296 ]\n",
            "  [ 0.30128506 -0.6138613  -1.7958736  ... -1.7538375   0.4280902\n",
            "    0.02597057]\n",
            "  [ 0.36920932 -0.29998782 -1.7132615  ...  0.6641271  -0.35159066\n",
            "   -1.1128763 ]]], shape=(1, 16, 128), dtype=float32)\n",
            "input lengths:  (1,)\n",
            "tf.Tensor([16], shape=(1,), dtype=int64)\n",
            "label lengths:  (1,)\n",
            "tf.Tensor([15], shape=(1,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=84.38543>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayrYFh54yG-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95dce611-6652-42fb-e536-2654787d5754"
      },
      "source": [
        "-np.log(0.99)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01005033585350145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    }
  ]
}