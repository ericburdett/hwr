{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnXtyXpnudAvewxthXtDRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/hwr/blob/master/notebook-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1NNlFTNfIP",
        "colab_type": "text"
      },
      "source": [
        "# Simple HWR - TensorFlow\n",
        "Implementation of Gated Convolutional Recurrent Neural Network for Handwriting Recognition as recorded in [Bluche](http://ieeexplore.ieee.org/document/8270042/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEofDy6iNq2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2fadf61-a25b-4022-a9bb-ead243c7409a"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxp4_ThN0OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c98c3c3f-8427-471b-82cf-be0872f2f848"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjM6wL9vCY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/iam.zip\" \"/content\"\n",
        "!unzip -q iam.zip\n",
        "!rm iam.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTb_wcEW4SFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder():\n",
        "  # input => (tuple of strings)\n",
        "  def get_representation(words):\n",
        "    charlists = []\n",
        "    zeros = np.zeros(20)\n",
        "\n",
        "    if type(words) == str:\n",
        "      charlist = [ord(c) for c in words]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "      return np.array(charlists)\n",
        "\n",
        "    for word in words:\n",
        "      charlist = [ord(c) for c in word]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "    return np.array(charlists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOMYB_3C4etl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "89411942-da9d-4044-9c28-c6806c3580be"
      },
      "source": [
        "Encoder.get_representation(('hello', 'world'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[104., 101., 108., 108., 111.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.],\n",
              "       [119., 111., 114., 108., 100.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt5fgIdznaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img, desired_size):\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "    # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "    # Solve by width\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  border_img = cv2.copyMakeBorder(\n",
        "      img,\n",
        "      top=border_top,\n",
        "      bottom=0,\n",
        "      left=0,\n",
        "      right=border_right,\n",
        "      borderType=cv2.BORDER_CONSTANT,\n",
        "      value=[255]\n",
        "  )\n",
        "\n",
        "  return border_img\n",
        "\n",
        "def tensor_image(path, desired_size):\n",
        "  img = Image.open(path + '.png')\n",
        "  img = resize(img, desired_size)\n",
        "  x = np.array(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def iam_generator(desired_size=(128, 32), path='/content/labels.csv'):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Iam dataset does not exist in ' + path)\n",
        "\n",
        "  df = pd.read_csv(path, sep='\\t', header=None, names=['word', 'seg', 'transcription'])\n",
        "  df = df.drop(['seg'], axis=1)\n",
        "  df = df.drop(df[df['transcription'] == '.'].index)\n",
        "  df = df.drop(df[df['transcription'] == '!'].index)\n",
        "  df = df.drop(df[df['transcription'] == ','].index)\n",
        "  df = df.drop(df[df['transcription'] == ';'].index)\n",
        "  df = df.drop(df[df['transcription'] == ':'].index)    \n",
        "  df = df.drop(df[df['transcription'] == ')'].index)\n",
        "  df = df.drop(df[df['transcription'] == '('].index)\n",
        "  df = df.reset_index()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'images/' + row['word'] + '.png'\n",
        "    img = Image.open(path)\n",
        "    img = resize_img(img, desired_size)\n",
        "    x = tf.convert_to_tensor(np.array(img))\n",
        "    y = tf.convert_to_tensor(Encoder.get_representation(row['transcription']))\n",
        "\n",
        "    yield(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEeoBJz69xQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0c0930b8-d065-4319-b773-d5597c49781f"
      },
      "source": [
        "t = tf.convert_to_tensor(np.array([[15, 15], [40, 40]]))\n",
        "tf.reshape(t, [-1, 2])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
              "array([[15, 15],\n",
              "       [40, 40]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ9iQ4jtyLON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_generator(\n",
        "    iam_generator,\n",
        "    (tf.int64, tf.int64),\n",
        "    (tf.TensorShape([None, None]), tf.TensorShape([None, 16]))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OrcVBQC87HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for elements in dataset.as_numpy_iterator():\n",
        "  print(elements)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7naHe62AGW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(Model):\n",
        "  def __init__(self):\n",
        "    super(Recognizer, self).__init__()\n",
        "    \n",
        "    # Encoder\n",
        "    self.conv1 = L.Conv2D(8, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv2 = L.Conv2D(16, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv3 = L.Conv2D(32, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv4 = L.Conv2D(64, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv5 = L.Conv2D(128, 3, strides=1, padding='same', activation='tanh')\n",
        "\n",
        "    self.gate1 = L.Conv2D(16, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate2 = L.Conv2D(32, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate3 = L.Conv2D(64, 3, strides=1, padding='same', activation='sigmoid')\n",
        "\n",
        "    # MaxPool\n",
        "    self.mp = L.MaxPool2D((32, 1))\n",
        "\n",
        "    # Decoder\n",
        "    self.gru1 = L.Bidirectional(L.GRU(256))\n",
        "    self.fc1 = L.Dense(128)\n",
        "    self.gru2 = L.Bidirectional(L.GRU(256))\n",
        "    self.fc2 = L.Dense(16)\n",
        "    self.softmax = L.Softmax(axis=1)\n",
        "    self.permute = L.Permute((2, 0, 1))\n",
        "\n",
        "  def call(self, x):\n",
        "    # Encoder\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(x)\n",
        "\n",
        "    g1 = self.gate1(out)\n",
        "    out = out * g1\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    \n",
        "    g2 = self.gate2(out)\n",
        "    out = out * g2\n",
        "\n",
        "    out = self.conv4(out)\n",
        "\n",
        "    g3 = self.gate3(out)\n",
        "    out = out * g3\n",
        "\n",
        "    out = self.conv5(out)\n",
        "\n",
        "    # Max Pooling across vertical dimension\n",
        "    out = self.mp(out)\n",
        "\n",
        "    # Decoder\n",
        "    out = tf.reshape(out, [-1, 128, 128])\n",
        "\n",
        "    out = self.gru1(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.gru2(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.softmax(out)\n",
        "    out = self.permute(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZx-iItZQ0D9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d2f838e-113b-4c1b-b240-65b8c67a2504"
      },
      "source": [
        "tf.convert_to_tensor(np.full((5,), 16))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([16, 16, 16, 16, 16])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka1khf0ZRZk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b20fcf8-6443-4b78-909d-1b515d6ac754"
      },
      "source": [
        "t = tf.constant([1, 41, 23, 4, 0, 0, 0, 0])\n",
        "t.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2zKBeJSFlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_lengths(tensors):\n",
        "  lengths = []\n",
        "\n",
        "  for tensor in tensors:\n",
        "    length = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAIwzQyJ_7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_size = images.shape[0]\n",
        "    input_lengths = tf.convert_to_tensor(np.full((batch_size,), 16))\n",
        "    label_lengths = tf.convert_to_tensor()\n",
        "    predictions = model(images)\n",
        "    loss = tf.nn.ctc_loss(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLQgNk4Td_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "e8e05b56-fcb6-4cb8-d368-476206f3bfba"
      },
      "source": [
        "t = tf.convert_to_tensor(tf.constant([[1, 2, 3]]))\n",
        "t"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2d59d56fd9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSA1f8pLq6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91dcf26c-c98a-42e6-90b4-4b22762607e8"
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataset = dataset.batch(BATCH_SIZE)\n",
        "for step, (x, y) in enumerate(train_dataset):\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "\n",
        "  break"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 128, 32)\n",
            "(1, 1, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}