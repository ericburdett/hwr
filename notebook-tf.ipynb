{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/hwr/blob/master/notebook-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1NNlFTNfIP",
        "colab_type": "text"
      },
      "source": [
        "# Simple HWR - TensorFlow\n",
        "\n",
        "A Handwriting Recognition implementation adapted from Flor.\n",
        "* [Blog Post](https://medium.com/@arthurflor23/handwritten-text-recognition-using-tensorflow-2-0-f4352b7afe16)\n",
        "* [GitHub](https://github.com/arthurflor23/handwritten-text-recognition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJu_T4cftV_3",
        "colab_type": "text"
      },
      "source": [
        "### Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEofDy6iNq2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxp4_ThN0OM",
        "colab_type": "code",
        "outputId": "644cf545-ce78-4f5c-b751-2938c05c0d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.constraints as C\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Data Structures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import html\n",
        "import numba as nb\n",
        "\n",
        "# Python\n",
        "import os\n",
        "import gc\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Image/Plotting\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Debugging\n",
        "from tqdm import tqdm\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjM6wL9vCY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/rimes-line-level.zip\" \"/content\"\n",
        "!cp \"drive/My Drive/datasets/iam-line-level.zip\" \"/content\"\n",
        "\n",
        "!unzip -q rimes-line-level.zip -d rimes\n",
        "!unzip -q iam-line-level.zip -d iam\n",
        "!rm iam-line-level.zip\n",
        "!rm rimes-line-level.zip\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/ericburdett/cs601r-dl/master/char_set.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwXlcWe2i4SX",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Code - Taken from arthurflor23/handwritten-text-recognition\n",
        "\n",
        "[Reference](https://github.com/arthurflor23/handwritten-text-recognition/blob/master/src/data/preproc.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVRRmfg-i3h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Data preproc functions:\n",
        "    adjust_to_see: adjust image to better visualize (rotate and transpose)\n",
        "    augmentation: apply variations to a list of images\n",
        "    normalization: apply normalization and variations on images (if required)\n",
        "    preprocess: main function for preprocess.\n",
        "        Make the image:\n",
        "            illumination_compensation: apply illumination regularitation\n",
        "            remove_cursive_style: remove cursive style from image (if necessary)\n",
        "            sauvola: apply sauvola binarization\n",
        "    text_standardize: preprocess and standardize sentence\n",
        "    generate_multigrams: generate n-grams of the sentence\n",
        "\"\"\"\n",
        "\n",
        "def adjust_to_see(img):\n",
        "    \"\"\"Rotate and transpose to image visualize (cv2 method or jupyter notebook)\"\"\"\n",
        "\n",
        "    (h, w) = img.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), -90, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "\n",
        "    img = cv2.warpAffine(img, M, (nW + 1, nH + 1))\n",
        "    img = cv2.warpAffine(img.transpose(), M, (nW, nH))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def augmentation(imgs,\n",
        "                 rotation_range=0,\n",
        "                 scale_range=0,\n",
        "                 height_shift_range=0,\n",
        "                 width_shift_range=0,\n",
        "                 dilate_range=1,\n",
        "                 erode_range=1):\n",
        "    \"\"\"Apply variations to a list of images (rotate, width and height shift, scale, erode, dilate)\"\"\"\n",
        "\n",
        "    imgs = imgs.astype(np.float32)\n",
        "    _, h, w = imgs.shape\n",
        "\n",
        "    dilate_kernel = np.ones((int(np.random.uniform(1, dilate_range)),), np.uint8)\n",
        "    erode_kernel = np.ones((int(np.random.uniform(1, erode_range)),), np.uint8)\n",
        "    height_shift = np.random.uniform(-height_shift_range, height_shift_range)\n",
        "    rotation = np.random.uniform(-rotation_range, rotation_range)\n",
        "    scale = np.random.uniform(1 - scale_range, 1)\n",
        "    width_shift = np.random.uniform(-width_shift_range, width_shift_range)\n",
        "\n",
        "    trans_map = np.float32([[1, 0, width_shift * w], [0, 1, height_shift * h]])\n",
        "    rot_map = cv2.getRotationMatrix2D((w // 2, h // 2), rotation, scale)\n",
        "\n",
        "    trans_map_aff = np.r_[trans_map, [[0, 0, 1]]]\n",
        "    rot_map_aff = np.r_[rot_map, [[0, 0, 1]]]\n",
        "    affine_mat = rot_map_aff.dot(trans_map_aff)[:2, :]\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        imgs[i] = cv2.warpAffine(imgs[i], affine_mat, (w, h), flags=cv2.INTER_NEAREST, borderValue=255)\n",
        "        imgs[i] = cv2.erode(imgs[i], erode_kernel, iterations=1)\n",
        "        imgs[i] = cv2.dilate(imgs[i], dilate_kernel, iterations=1)\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def normalization(imgs):\n",
        "    \"\"\"Normalize list of images\"\"\"\n",
        "\n",
        "    imgs = np.asarray(imgs).astype(np.float32)\n",
        "    _, h, w = imgs.shape\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        m, s = cv2.meanStdDev(imgs[i])\n",
        "        imgs[i] = imgs[i] - m[0][0]\n",
        "        imgs[i] = imgs[i] / s[0][0] if s[0][0] > 0 else imgs[i]\n",
        "\n",
        "    return np.expand_dims(imgs, axis=-1)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Preprocess metodology based in:\n",
        "    H. Scheidl, S. Fiel and R. Sablatnig,\n",
        "    Word Beam Search: A Connectionist Temporal Classification Decoding Algorithm, in\n",
        "    16th International Conference on Frontiers in Handwriting Recognition, pp. 256-258, 2018.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def preprocess(img, input_size):\n",
        "    \"\"\"Make the process with the `input_size` to the scale resize\"\"\"\n",
        "\n",
        "    if isinstance(img, str):\n",
        "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if isinstance(img, tuple):\n",
        "        image, boundbox = img\n",
        "        img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        for i in range(len(boundbox)):\n",
        "            if isinstance(boundbox[i], float):\n",
        "                total = len(img) if i < 2 else len(img[0])\n",
        "                boundbox[i] = int(total * boundbox[i])\n",
        "\n",
        "        img = np.asarray(img[boundbox[0]:boundbox[1], boundbox[2]:boundbox[3]], dtype=np.uint8)\n",
        "\n",
        "    wt, ht, _ = input_size\n",
        "    h, w = np.asarray(img).shape\n",
        "    f = max((w / wt), (h / ht))\n",
        "\n",
        "    new_size = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1))\n",
        "    img = cv2.resize(img, new_size)\n",
        "\n",
        "    _, binary = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    if np.sum(img) * 0.8 > np.sum(binary):\n",
        "        img = illumination_compensation(img)\n",
        "\n",
        "    img = remove_cursive_style(img)\n",
        "\n",
        "    target = np.ones([ht, wt], dtype=np.uint8) * 255\n",
        "    target[0:new_size[1], 0:new_size[0]] = img\n",
        "    img = cv2.transpose(target)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Illumination Compensation based in:\n",
        "    K.-N. Chen, C.-H. Chen, C.-C. Chang,\n",
        "    Efficient illumination compensation techniques for text images, in\n",
        "    Digital Signal Processing, 22(5), pp. 726-733, 2012.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def illumination_compensation(img):\n",
        "    \"\"\"Illumination compensation technique for text image\"\"\"\n",
        "\n",
        "    def scale(img):\n",
        "        s = np.max(img) - np.min(img)\n",
        "        res = img / s\n",
        "        res -= np.min(res)\n",
        "        res *= 255\n",
        "        return res\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    height, width = img.shape\n",
        "    sqrt_hw = np.sqrt(height * width)\n",
        "\n",
        "    bins = np.arange(0, 300, 10)\n",
        "    bins[26] = 255\n",
        "    hp = np.histogram(img, bins)\n",
        "    for i in range(len(hp[0])):\n",
        "        if hp[0][i] > sqrt_hw:\n",
        "            hr = i * 10\n",
        "            break\n",
        "\n",
        "    np.seterr(divide='ignore', invalid='ignore')\n",
        "    cei = (img - (hr + 50 * 0.3)) * 2\n",
        "    cei[cei > 255] = 255\n",
        "    cei[cei < 0] = 0\n",
        "\n",
        "    m1 = np.asarray([-1, 0, 1, -2, 0, 2, -1, 0, 1]).reshape((3, 3))\n",
        "    m2 = np.asarray([-2, -1, 0, -1, 0, 1, 0, 1, 2]).reshape((3, 3))\n",
        "    m3 = np.asarray([-1, -2, -1, 0, 0, 0, 1, 2, 1]).reshape((3, 3))\n",
        "    m4 = np.asarray([0, 1, 2, -1, 0, 1, -2, -1, 0]).reshape((3, 3))\n",
        "\n",
        "    eg1 = np.abs(cv2.filter2D(img, -1, m1))\n",
        "    eg2 = np.abs(cv2.filter2D(img, -1, m2))\n",
        "    eg3 = np.abs(cv2.filter2D(img, -1, m3))\n",
        "    eg4 = np.abs(cv2.filter2D(img, -1, m4))\n",
        "\n",
        "    eg_avg = scale((eg1 + eg2 + eg3 + eg4) / 4)\n",
        "\n",
        "    h, w = eg_avg.shape\n",
        "    eg_bin = np.zeros((h, w))\n",
        "    eg_bin[eg_avg >= 30] = 255\n",
        "\n",
        "    h, w = cei.shape\n",
        "    cei_bin = np.zeros((h, w))\n",
        "    cei_bin[cei >= 60] = 255\n",
        "\n",
        "    h, w = eg_bin.shape\n",
        "    tli = 255 * np.ones((h, w))\n",
        "    tli[eg_bin == 255] = 0\n",
        "    tli[cei_bin == 255] = 0\n",
        "\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    erosion = cv2.erode(tli, kernel, iterations=1)\n",
        "    int_img = np.asarray(cei)\n",
        "\n",
        "    estimate_light_distribution(width, height, erosion, cei, int_img)\n",
        "\n",
        "    mean_filter = 1 / 121 * np.ones((11, 11), np.uint8)\n",
        "    ldi = cv2.filter2D(scale(int_img), -1, mean_filter)\n",
        "\n",
        "    result = np.divide(cei, ldi) * 260\n",
        "    result[erosion != 0] *= 1.5\n",
        "    result[result < 0] = 0\n",
        "    result[result > 255] = 255\n",
        "\n",
        "    return np.asarray(result, dtype=np.uint8)\n",
        "\n",
        "\n",
        "@nb.jit(nopython=True)\n",
        "def estimate_light_distribution(width, height, erosion, cei, int_img):\n",
        "    \"\"\"Light distribution performed by numba (thanks @Sundrops)\"\"\"\n",
        "\n",
        "    for y in range(width):\n",
        "        for x in range(height):\n",
        "            if erosion[x][y] == 0:\n",
        "                i = x\n",
        "\n",
        "                while i < erosion.shape[0] and erosion[i][y] == 0:\n",
        "                    i += 1\n",
        "\n",
        "                end = i - 1\n",
        "                n = end - x + 1\n",
        "\n",
        "                if n <= 30:\n",
        "                    h, e = [], []\n",
        "\n",
        "                    for k in range(5):\n",
        "                        if x - k >= 0:\n",
        "                            h.append(cei[x - k][y])\n",
        "\n",
        "                        if end + k < cei.shape[0]:\n",
        "                            e.append(cei[end + k][y])\n",
        "\n",
        "                    mpv_h, mpv_e = max(h), max(e)\n",
        "\n",
        "                    for m in range(n):\n",
        "                        int_img[x + m][y] = mpv_h + (m + 1) * ((mpv_e - mpv_h) / n)\n",
        "\n",
        "                x = end\n",
        "                break\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Deslating image process based in,\n",
        "    A. Vinciarelli and J. Luettin,\n",
        "    A New Normalization Technique for Cursive Handwritten Wrods, in\n",
        "    Pattern Recognition, 22, 2001.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def remove_cursive_style(img):\n",
        "    \"\"\"Remove cursive writing style from image with deslanting algorithm\"\"\"\n",
        "\n",
        "    def calc_y_alpha(vec):\n",
        "        indices = np.where(vec > 0)[0]\n",
        "        h_alpha = len(indices)\n",
        "\n",
        "        if h_alpha > 0:\n",
        "            delta_y_alpha = indices[h_alpha - 1] - indices[0] + 1\n",
        "\n",
        "            if h_alpha == delta_y_alpha:\n",
        "                return h_alpha * h_alpha\n",
        "        return 0\n",
        "\n",
        "    alpha_vals = [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "    rows, cols = img.shape\n",
        "    results = []\n",
        "\n",
        "    ret, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    binary = otsu if ret < 127 else sauvola(img, (int(img.shape[0] / 2), int(img.shape[0] / 2)), 127, 1e-2)\n",
        "\n",
        "    for alpha in alpha_vals:\n",
        "        shift_x = max(-alpha * rows, 0.)\n",
        "        size = (cols + int(np.ceil(abs(alpha * rows))), rows)\n",
        "        transform = np.asarray([[1, alpha, shift_x], [0, 1, 0]], dtype=np.float)\n",
        "\n",
        "        shear_img = cv2.warpAffine(binary, transform, size, cv2.INTER_NEAREST)\n",
        "        sum_alpha = 0\n",
        "        sum_alpha += np.apply_along_axis(calc_y_alpha, 0, shear_img)\n",
        "        results.append([np.sum(sum_alpha), size, transform])\n",
        "\n",
        "    result = sorted(results, key=lambda x: x[0], reverse=True)[0]\n",
        "    warp = cv2.warpAffine(img, result[2], result[1], borderValue=255)\n",
        "\n",
        "    return cv2.resize(warp, dsize=(cols, rows))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Sauvola binarization based in,\n",
        "    J. Sauvola, T. Seppanen, S. Haapakoski, M. Pietikainen,\n",
        "    Adaptive Document Binarization, in IEEE Computer Society Washington, 1997.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def sauvola(img, window, thresh, k):\n",
        "    \"\"\"Sauvola binarization\"\"\"\n",
        "\n",
        "    rows, cols = img.shape\n",
        "    pad = int(np.floor(window[0] / 2))\n",
        "    sum2, sqsum = cv2.integral2(\n",
        "        cv2.copyMakeBorder(img, pad, pad, pad, pad, cv2.BORDER_CONSTANT))\n",
        "\n",
        "    isum = sum2[window[0]:rows + window[0], window[1]:cols + window[1]] + \\\n",
        "        sum2[0:rows, 0:cols] - \\\n",
        "        sum2[window[0]:rows + window[0], 0:cols] - \\\n",
        "        sum2[0:rows, window[1]:cols + window[1]]\n",
        "\n",
        "    isqsum = sqsum[window[0]:rows + window[0], window[1]:cols + window[1]] + \\\n",
        "        sqsum[0:rows, 0:cols] - \\\n",
        "        sqsum[window[0]:rows + window[0], 0:cols] - \\\n",
        "        sqsum[0:rows, window[1]:cols + window[1]]\n",
        "\n",
        "    ksize = window[0] * window[1]\n",
        "    mean = isum / ksize\n",
        "    std = (((isqsum / ksize) - (mean**2) / ksize) / ksize) ** 0.5\n",
        "    threshold = (mean * (1 + k * (std / thresh - 1))) * (mean >= 100)\n",
        "\n",
        "    return np.asarray(255 * (img >= threshold), 'uint8')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DeepSpell based text cleaning process.\n",
        "    Tal Weiss.\n",
        "    Deep Spelling.\n",
        "    Medium: https://machinelearnings.co/deep-spelling-9ffef96a24f6#.2c9pu8nlm\n",
        "    Github: https://github.com/MajorTal/DeepSpell\n",
        "\"\"\"\n",
        "\n",
        "RE_DASH_FILTER = re.compile(r'[\\-\\˗\\֊\\‐\\‑\\‒\\–\\—\\⁻\\₋\\−\\﹣\\－]', re.UNICODE)\n",
        "RE_APOSTROPHE_FILTER = re.compile(r'&#39;|[ʼ՚＇‘’‛❛❜ߴߵ`‵´ˊˋ{}{}{}{}{}{}{}{}{}]'.format(\n",
        "    chr(768), chr(769), chr(832), chr(833), chr(2387),\n",
        "    chr(5151), chr(5152), chr(65344), chr(8242)), re.UNICODE)\n",
        "RE_RESERVED_CHAR_FILTER = re.compile(r'[¶¤«»]', re.UNICODE)\n",
        "RE_LEFT_PARENTH_FILTER = re.compile(r'[\\(\\[\\{\\⁽\\₍\\❨\\❪\\﹙\\（]', re.UNICODE)\n",
        "RE_RIGHT_PARENTH_FILTER = re.compile(r'[\\)\\]\\}\\⁾\\₎\\❩\\❫\\﹚\\）]', re.UNICODE)\n",
        "RE_BASIC_CLEANER = re.compile(r'[^\\w\\s{}]'.format(re.escape(string.punctuation)), re.UNICODE)\n",
        "\n",
        "LEFT_PUNCTUATION_FILTER = \"\"\"!%&),.:;<=>?@\\\\]^_`|}~\"\"\"\n",
        "RIGHT_PUNCTUATION_FILTER = \"\"\"\"(/<=>@[\\\\^_`{|~\"\"\"\n",
        "NORMALIZE_WHITESPACE_REGEX = re.compile(r'[^\\S\\n]+', re.UNICODE)\n",
        "\n",
        "\n",
        "def text_standardize(text):\n",
        "    \"\"\"Organize/add spaces around punctuation marks\"\"\"\n",
        "\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "\n",
        "    text = html.unescape(text).replace(\"\\\\n\", \"\").replace(\"\\\\t\", \"\")\n",
        "\n",
        "    text = RE_RESERVED_CHAR_FILTER.sub(\"\", text)\n",
        "    text = RE_DASH_FILTER.sub(\"-\", text)\n",
        "    text = RE_APOSTROPHE_FILTER.sub(\"'\", text)\n",
        "    text = RE_LEFT_PARENTH_FILTER.sub(\"(\", text)\n",
        "    text = RE_RIGHT_PARENTH_FILTER.sub(\")\", text)\n",
        "    text = RE_BASIC_CLEANER.sub(\"\", text)\n",
        "\n",
        "    text = text.lstrip(LEFT_PUNCTUATION_FILTER)\n",
        "    text = text.rstrip(RIGHT_PUNCTUATION_FILTER)\n",
        "    text = text.translate(str.maketrans({c: f\" {c} \" for c in string.punctuation}))\n",
        "    text = NORMALIZE_WHITESPACE_REGEX.sub(\" \", text.strip())\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def generate_multigrams(sentence):\n",
        "    \"\"\"\n",
        "    Generate n-grams of the sentence.\n",
        "    i.e.:\n",
        "    original sentence: I like code .\n",
        "        > sentence 1 : I like\n",
        "        > sentence 2 : I like code .\n",
        "        > sentence 3 : like\n",
        "        > sentence 4 : like code .\n",
        "        > sentence 5 : code .\n",
        "    \"\"\"\n",
        "\n",
        "    tokens = sentence.split()\n",
        "    tk_length = len(tokens)\n",
        "    multigrams = []\n",
        "\n",
        "    for y in range(tk_length):\n",
        "        new_sentence = True\n",
        "        support_text = \"\"\n",
        "\n",
        "        for x in range(y, tk_length):\n",
        "            if y == 0 and tk_length > 2 and x == (tk_length - 1):\n",
        "                continue\n",
        "\n",
        "            if len(tokens[x]) <= 2 and tokens[x] != tokens[-1]:\n",
        "                support_text += f\" {tokens[x]}\"\n",
        "                continue\n",
        "\n",
        "            last = \"\"\n",
        "            if x > y and len(multigrams) > 0 and not new_sentence:\n",
        "                last = multigrams[-1]\n",
        "\n",
        "            multigrams.append(f\"{last}{support_text} {tokens[x]}\".strip())\n",
        "            new_sentence = False\n",
        "            support_text = \"\"\n",
        "\n",
        "    return multigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SecTIXujtiUG",
        "colab_type": "text"
      },
      "source": [
        "### Dataset and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTb_wcEW4SFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder():\n",
        "  def __init__(self, sequence_size=150):\n",
        "    with open('char_set.json') as file:\n",
        "      self.json = json.load(file)\n",
        "    \n",
        "    self.sequence_size = sequence_size\n",
        "\n",
        "  def remove_duplicates(self, idxs):\n",
        "    new_idxs = []\n",
        "\n",
        "    for i in range(len(idxs)):\n",
        "      if i + 1 == len(idxs) or idxs[i] != idxs[i + 1]:\n",
        "        new_idxs.append(idxs[i])\n",
        "    \n",
        "    return new_idxs\n",
        "  \n",
        "  def add_blanks(self, idxs):\n",
        "    new_idxs = []\n",
        "\n",
        "    for i in range(len(idxs)):\n",
        "      new_idxs.append(idxs[i])\n",
        "      if i + 1 != len(idxs) and idxs[i] == idxs[i + 1]:\n",
        "        new_idxs.append(0)\n",
        "    \n",
        "    return new_idxs\n",
        "  \n",
        "  def idx_to_char(self, idx):\n",
        "    if idx == 0:\n",
        "      return ''\n",
        "    else:\n",
        "      return self.json['idx_to_char'][str(int(idx))]\n",
        "  \n",
        "  def char_to_idx(self, char):\n",
        "    return int(self.json['char_to_idx'][char])\n",
        "  \n",
        "  def str_to_idxs(self, string):\n",
        "    idxs = []\n",
        "\n",
        "    zeros = np.zeros(self.sequence_size)\n",
        "\n",
        "    for char in string:\n",
        "      idxs.append(self.char_to_idx(char))\n",
        "\n",
        "    # Add blanks if CTC-Loss requires it...\n",
        "    # idxs = self.add_blanks(idxs)\n",
        "\n",
        "    idxs = np.concatenate((idxs, zeros))[:self.sequence_size]\n",
        "    \n",
        "    return idxs\n",
        "\n",
        "  def idxs_to_str(self, idxs):\n",
        "    string = ''\n",
        "    idxs = self.remove_duplicates(idxs)\n",
        "\n",
        "    for idx in idxs:\n",
        "      string += self.idx_to_char(idx)\n",
        "    \n",
        "    return string\n",
        "  \n",
        "  def str_to_idxs_batch(self, batch):\n",
        "    idxs = []\n",
        "\n",
        "    for string in batch:\n",
        "      idx = self.str_to_idxs(string)\n",
        "      idxs.append(idx)\n",
        "\n",
        "      return idxs\n",
        "  \n",
        "  def idxs_to_str_batch(self, batch):\n",
        "    strings = []\n",
        "\n",
        "    for idxs in batch:\n",
        "      strings.append(self.idxs_to_str(idxs))\n",
        "    \n",
        "    return strings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt5fgIdznaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_imgs(x, new_fig=True):\n",
        "  if new_fig:\n",
        "    plt.figure()\n",
        "  plt.imshow(x)\n",
        "  plt.pause(1)\n",
        "\n",
        "def resize(img, desired_size):\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "    # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "    # Solve by width\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  img = np.pad(img, [(border_top, 0), (0, border_right)], mode='constant', constant_values=255)\n",
        "\n",
        "  return img\n",
        "\n",
        "def tensor_image(path, desired_size):\n",
        "  img = Image.open(path + '.png')\n",
        "  img = resize(img, desired_size)\n",
        "  x = np.array(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def get_iam_dataset_df(path='/content/iam/labels.csv', total_imgs=None):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Iam dataset does not exist in ' + path)\n",
        "\n",
        "  img_path = '/content/iam/images/'\n",
        "  df = pd.read_csv('/content/iam/labels.csv', header=None, sep='\\t', names=['word', 'transcription'], quoting=csv.QUOTE_NONE)\n",
        "  df = df.sample(frac=1).reset_index(drop=True) # Shuffle the dataframe\n",
        "  if total_imgs != None:\n",
        "    self.df = df[:total_imgs]\n",
        "\n",
        "  return df\n",
        "\n",
        "def get_rimes_dataset_df(path='/content/rimes/labels.csv', total_imgs=None):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Rimes dataset does not exist in ' + path)\n",
        "\n",
        "  img_path = '/content/rimes/images/'\n",
        "  df = pd.read_csv('/content/rimes/labels.csv', header=None, sep='\\t', names=['word', 'transcription'], quoting=csv.QUOTE_NONE)\n",
        "  df = df.sample(frac=1).reset_index(drop=True) # Shuffle the dataframe\n",
        "  if total_imgs != None:\n",
        "    self.df = df[:total_imgs]\n",
        "\n",
        "  return df\n",
        "\n",
        "def rimes_generator(desired_size=(1024, 64, 1)):\n",
        "  df = get_rimes_dataset_df()\n",
        "\n",
        "  encoder = Encoder(sequence_size=128)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'rimes/images/' + row['word']\n",
        "    img = cv2.imread(path, 0)\n",
        "    # img = Image.open(path)\n",
        "    # img = resize(img, desired_size)\n",
        "    img = preprocess(img, desired_size)\n",
        "    x = tf.expand_dims(tf.convert_to_tensor(np.array(img), dtype=tf.float32), 2)\n",
        "    y = tf.convert_to_tensor(encoder.str_to_idxs(row['transcription']), dtype=tf.int32)\n",
        "\n",
        "    yield(x, y)\n",
        "\n",
        "def iam_generator(desired_size=(1024, 64, 1)):\n",
        "  df = get_iam_dataset_df()\n",
        "\n",
        "  encoder = Encoder(sequence_size=128)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'iam/images/' + row['word'] + '.png'\n",
        "    img = cv2.imread(path, 0)\n",
        "    # img = Image.open(path)\n",
        "    # img = resize(img, desired_size)\n",
        "    img = preprocess(img, desired_size)\n",
        "\n",
        "    x = tf.expand_dims(tf.convert_to_tensor(np.array(img), dtype=tf.float32), 2)\n",
        "    y = tf.convert_to_tensor(encoder.str_to_idxs(row['transcription']), dtype=tf.int32)\n",
        "\n",
        "    yield(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-EA9Ph25tG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  for x, y in rimes_generator():\n",
        "    img = tf.squeeze(x)\n",
        "    print(img.shape)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(tf.transpose(img, [1,0]), cmap='gray')\n",
        "    plt.pause(2)\n",
        "except:\n",
        "  __ITB__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CVBrqGztrVi",
        "colab_type": "text"
      },
      "source": [
        "### Recognition Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPJRea4lFIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullGatedConv2D(L.Conv2D):\n",
        "    \"\"\"Gated Convolutional Class\"\"\"\n",
        "\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(FullGatedConv2D, self).__init__(filters=filters * 2, **kwargs)\n",
        "        self.nb_filters = filters\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Apply gated convolution\"\"\"\n",
        "\n",
        "        output = super(FullGatedConv2D, self).call(inputs)\n",
        "        linear = L.Activation(\"linear\")(output[:, :, :, :self.nb_filters])\n",
        "        sigmoid = L.Activation(\"sigmoid\")(output[:, :, :, self.nb_filters:])\n",
        "\n",
        "        return L.Multiply()([linear, sigmoid])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Compute shape of layer output\"\"\"\n",
        "\n",
        "        output_shape = super(FullGatedConv2D, self).compute_output_shape(input_shape)\n",
        "        return tuple(output_shape[:3]) + (self.nb_filters,)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Return the config of the layer\"\"\"\n",
        "\n",
        "        config = super(FullGatedConv2D, self).get_config()\n",
        "        config['nb_filters'] = self.nb_filters\n",
        "        del config['filters']\n",
        "        return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7naHe62AGW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(Model):\n",
        "  def __init__(self, sequence_size=128, vocabulary_size=197):\n",
        "    super(Recognizer, self).__init__(name='flor_recognizer')\n",
        "\n",
        "    self.conv1 = tf.keras.Sequential(name='conv1')\n",
        "    self.conv1.add(L.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv1.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv1.add(L.BatchNormalization(renorm=True))\n",
        "    self.conv1.add(FullGatedConv2D(filters=16, kernel_size=(3,3), padding=\"same\"))\n",
        "    \n",
        "    self.conv2 = tf.keras.Sequential(name='conv2')\n",
        "    self.conv2.add(L.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv2.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv2.add(L.BatchNormalization(renorm=True))\n",
        "    self.conv2.add(FullGatedConv2D(filters=32, kernel_size=(3,3), padding=\"same\"))\n",
        "\n",
        "    self.conv3 = tf.keras.Sequential(name='conv3')\n",
        "    self.conv3.add(L.Conv2D(filters=40, kernel_size=(2,4), strides=(2,4), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv3.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv3.add(L.BatchNormalization(renorm=True))\n",
        "    self.conv3.add(FullGatedConv2D(filters=40, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout1 = L.Dropout(rate=0.2, name='dropout1')\n",
        "\n",
        "    self.conv4 = tf.keras.Sequential(name='conv4')\n",
        "    self.conv4.add(L.Conv2D(filters=48, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv4.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv4.add(L.BatchNormalization(renorm=True))\n",
        "    self.conv4.add(FullGatedConv2D(filters=48, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout2 = L.Dropout(rate=0.2, name='dropout2')\n",
        "\n",
        "    self.conv5 = tf.keras.Sequential(name='conv5')\n",
        "    self.conv5.add(L.Conv2D(filters=56, kernel_size=(2,4), strides=(2,4), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv5.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv5.add(L.BatchNormalization(renorm=True))\n",
        "    self.conv5.add(FullGatedConv2D(filters=56, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout3 = L.Dropout(rate=0.2, name='dropout3')\n",
        "\n",
        "    self.conv6 = tf.keras.Sequential(name='conv6')\n",
        "    self.conv6.add(L.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv6.add(L.PReLU(shared_axes=[1,2]))\n",
        "    self.conv6.add(L.BatchNormalization(renorm=True))\n",
        "    \n",
        "    self.mp = L.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding=\"valid\", name='mp')\n",
        "\n",
        "    self.gru1 = tf.keras.Sequential(name='gru1')\n",
        "    self.gru1.add(L.Bidirectional(L.GRU(units=128, return_sequences=True, dropout=0.5)))\n",
        "    self.gru1.add(L.Dense(units=256))\n",
        "    self.gru1.add(L.ReLU())\n",
        "\n",
        "    self.gru2 = tf.keras.Sequential(name='gru2')\n",
        "    self.gru2.add(L.Bidirectional(L.GRU(units=128, return_sequences=True, dropout=0.5)))\n",
        "    self.gru2.add(L.Dense(units=vocabulary_size))\n",
        "    \n",
        "  def call(self, x, training=False):\n",
        "    # CNN\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.dropout1(out, training=training)\n",
        "    out = self.conv4(out)\n",
        "    out = self.dropout2(out, training=training)\n",
        "    out = self.conv5(out)\n",
        "    out = self.dropout3(out, training=training)\n",
        "    out = self.conv6(out)\n",
        "\n",
        "    # MaxPool and Reshape\n",
        "    out = self.mp(out)\n",
        "    # out = tf.squeeze(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[1], out.shape[2] * out.shape[3]))\n",
        "\n",
        "    # RNN\n",
        "    out = self.gru1(out)\n",
        "    out = self.gru2(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ah_zuHM8hJG",
        "colab_type": "code",
        "outputId": "77c53d4e-90e3-4575-fe42-11520a3b6abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gen = rimes_generator()\n",
        "\n",
        "model = Recognizer()\n",
        "ten, _ = next(gen)\n",
        "ten = tf.expand_dims(ten, 0)\n",
        "# Input Shape\n",
        "ten.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1024, 64, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqJDptg8C-Q8",
        "colab_type": "code",
        "outputId": "38f3c078-19ec-49b9-fe58-94cccd0b5073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Output Shape\n",
        "model(ten).shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 128, 197])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDcQPHKYicCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "2fb96ca8-8c63-4fec-8a06-480da4fba2ad"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"flor_recognizer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Sequential)           multiple                  4928      \n",
            "_________________________________________________________________\n",
            "conv2 (Sequential)           multiple                  23392     \n",
            "_________________________________________________________________\n",
            "conv3 (Sequential)           multiple                  39480     \n",
            "_________________________________________________________________\n",
            "dropout1 (Dropout)           multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv4 (Sequential)           multiple                  59280     \n",
            "_________________________________________________________________\n",
            "dropout2 (Dropout)           multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv5 (Sequential)           multiple                  78568     \n",
            "_________________________________________________________________\n",
            "dropout3 (Dropout)           multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv6 (Sequential)           multiple                  32832     \n",
            "_________________________________________________________________\n",
            "mp (MaxPooling2D)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "gru1 (Sequential)            multiple                  214784    \n",
            "_________________________________________________________________\n",
            "gru2 (Sequential)            multiple                  347077    \n",
            "=================================================================\n",
            "Total params: 800,341\n",
            "Trainable params: 799,061\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQGqEkCkttSs",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ylbhm0oyuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Train:\n",
        "  def __init__(self):\n",
        "    self.epochs = 100\n",
        "    self.batch_size = 64\n",
        "    self.iteration_sample = 5000\n",
        "\n",
        "    dataset_size = len(get_iam_dataset_df())\n",
        "    self.val_dataset_size = int(.2 * dataset_size)\n",
        "    self.train_dataset_size = dataset_size - self.val_dataset_size\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        iam_generator,\n",
        "        (tf.float32, tf.int32),\n",
        "        (tf.TensorShape([None, None, 1]), tf.TensorShape([128]))\n",
        "    )\n",
        "    self.val_dataset = dataset.take(self.val_dataset_size).batch(self.batch_size)\n",
        "    self.train_dataset = dataset.skip(self.val_dataset_size).batch(self.batch_size)\n",
        "\n",
        "    self.model = Recognizer()\n",
        "    self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=4e-4)\n",
        "\n",
        "    self.encoder = Encoder(sequence_size=128)\n",
        "\n",
        "    self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    self.val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      iter_batch_size = images.shape[0]\n",
        "\n",
        "      input_lengths = tf.constant(np.full((iter_batch_size,), 128))\n",
        "      label_lengths = tf.math.count_nonzero(labels, axis=1)\n",
        "      unique_lengths = tf.nn.ctc_unique_labels(labels)\n",
        "\n",
        "      predictions = self.model(images, training=True)\n",
        "\n",
        "      loss = tf.nn.ctc_loss(labels, predictions, label_lengths, input_lengths, logits_time_major=False, unique=unique_lengths)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "    \n",
        "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "    self.train_loss(loss)\n",
        "\n",
        "  @tf.function\n",
        "  def validation_step(self, images, labels):\n",
        "    iter_batch_size = images.shape[0]\n",
        "\n",
        "    input_lengths = tf.constant(np.full((iter_batch_size,), 128))\n",
        "    label_lengths = tf.math.count_nonzero(labels, axis=1)\n",
        "    unique_lengths = tf.nn.ctc_unique_labels(labels)\n",
        "\n",
        "    predictions = self.model(images)\n",
        "\n",
        "    loss = tf.nn.ctc_loss(labels, predictions, label_lengths, input_lengths, logits_time_major=False, unique=unique_lengths)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "\n",
        "    self.val_loss(loss)\n",
        "\n",
        "  def __call__(self):\n",
        "    try:\n",
        "      train_losses, val_losses = [], []\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "        self.train_loss.reset_states()\n",
        "        self.val_loss.reset_states()\n",
        "\n",
        "        train_epoch_losses, val_epoch_losses = [], []\n",
        "\n",
        "        # Train Step\n",
        "        train_loop = tqdm(total=self.train_dataset_size//self.batch_size, position=0, leave=True)\n",
        "        for iteration_num, (images, labels) in enumerate(self.train_dataset):\n",
        "          self.train_step(images, labels)\n",
        "          train_epoch_losses.append(self.train_loss.result())\n",
        "          avg_loss = np.mean(train_epoch_losses) if len(train_epoch_losses) != 0 else 0 \n",
        "          train_loop.set_description('Train - Epoch: {}, Loss: {:.4f}, AvgLoss: {:.4f}'.format(epoch, self.train_loss.result(), avg_loss))\n",
        "          train_loop.update(1)\n",
        "\n",
        "        train_loop.close()\n",
        "\n",
        "        train_losses.append(np.mean(train_epoch_losses))\n",
        "        val_losses.append(np.mean(val_epoch_losses))\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        # # Validation Step\n",
        "        # val_loop = tqdm(total=self.val_dataset_size//self.batch_size, position=0, leave=True)\n",
        "        # for iteration_num, (images, labels) in enumerate(self.val_dataset):\n",
        "        #   self.val_step(images, labels)\n",
        "        #   val_epoch_losses.append(self.val_loss.result())\n",
        "        #   avg_loss = np.mean(val_epoch_losses) if len(val_epoch_losses) != 0 else 0\n",
        "        #   val_loop.set_description('Val   - Epoch: {}, Loss: {:.4f}, AvgLoss: {:.4f}'.format(epoch, self.val_loss.result(), avg_loss))\n",
        "        #   val_loop.update(1)\n",
        "\n",
        "        # val_loop.close()\n",
        "    except:\n",
        "      __ITB__()\n",
        "    finally:\n",
        "      return self.model, (train_losses, val_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFtyvVVQqj2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "25bcc1e5-927f-4b12-9169-667a8ce035ca"
      },
      "source": [
        "train = Train()\n",
        "model, losses = train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Epoch: 0, Loss: 149.1752, AvgLoss: 184.1358: : 142it [16:34,  7.01s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "Train - Epoch: 1, Loss: 133.1094, AvgLoss: 134.7211:  48%|████▊     | 67/141 [09:08<07:04,  5.73s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wre7v6ut2v3",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf8ivUgElQm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    iam_generator,\n",
        "    (tf.float32, tf.int32),\n",
        "    (tf.TensorShape([None, None, 1]), tf.TensorShape([128]))\n",
        ").batch(1)\n",
        "\n",
        "encoder = Encoder(sequence_size=128)\n",
        "\n",
        "for iteration_num, (images, labels) in enumerate(val_dataset):\n",
        "  if iteration_num == 20:\n",
        "    break\n",
        "\n",
        "  input_lengths = tf.constant(np.full((1,), 197), dtype=tf.int32)\n",
        "  preds = model(images)\n",
        "  preds_strings = encoder.idxs_to_str_batch(tf.argmax(preds, axis=2))\n",
        "  target_strings = encoder.idxs_to_str_batch(labels)\n",
        "\n",
        "  print('Predicted: ', preds_strings[:1])\n",
        "  print('Target: ', target_strings[:1])\n",
        "  show_imgs(tf.squeeze(images[:1]))\n",
        "  plt.pause(1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}