{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSkohyeIYwAEwSGsh52pY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/hwr/blob/master/notebook-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1NNlFTNfIP",
        "colab_type": "text"
      },
      "source": [
        "# Simple HWR - TensorFlow\n",
        "Implementation of Gated Convolutional Recurrent Neural Network for Handwriting Recognition as recorded in [Bluche](http://ieeexplore.ieee.org/document/8270042/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEofDy6iNq2F",
        "colab_type": "code",
        "outputId": "41477e4e-db06-4b1a-c599-0d1bc4df5dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxp4_ThN0OM",
        "colab_type": "code",
        "outputId": "332d36d9-c0a3-4ebd-cda5-3d2752cdcc18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjM6wL9vCY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/iam.zip\" \"/content\"\n",
        "!unzip -q iam.zip\n",
        "!rm iam.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTb_wcEW4SFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder():\n",
        "  # input => (tuple of strings)\n",
        "  def get_representation(words):\n",
        "    charlists = []\n",
        "    zeros = np.zeros(20)\n",
        "\n",
        "    if type(words) == str:\n",
        "      charlist = [ord(c) for c in words]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "      return np.array(charlists)\n",
        "\n",
        "    for word in words:\n",
        "      charlist = [ord(c) for c in word]\n",
        "      charlist = np.concatenate((charlist, zeros))\n",
        "      charlists.append(charlist[:16])\n",
        "\n",
        "    return np.array(charlists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt5fgIdznaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img, desired_size):\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "    # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "    # Solve by width\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  border_img = cv2.copyMakeBorder(\n",
        "      img,\n",
        "      top=border_top,\n",
        "      bottom=0,\n",
        "      left=0,\n",
        "      right=border_right,\n",
        "      borderType=cv2.BORDER_CONSTANT,\n",
        "      value=[255]\n",
        "  )\n",
        "\n",
        "  return border_img\n",
        "\n",
        "def tensor_image(path, desired_size):\n",
        "  img = Image.open(path + '.png')\n",
        "  img = resize(img, desired_size)\n",
        "  x = np.array(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def iam_generator(desired_size=(128, 32), path='/content/labels.csv'):\n",
        "  if not os.path.exists(path):\n",
        "    raise Exception('Iam dataset does not exist in ' + path)\n",
        "\n",
        "  df = pd.read_csv(path, sep='\\t', header=None, names=['word', 'seg', 'transcription'])\n",
        "  df = df.drop(['seg'], axis=1)\n",
        "  df = df.drop(df[df['transcription'] == '.'].index)\n",
        "  df = df.drop(df[df['transcription'] == '!'].index)\n",
        "  df = df.drop(df[df['transcription'] == ','].index)\n",
        "  df = df.drop(df[df['transcription'] == ';'].index)\n",
        "  df = df.drop(df[df['transcription'] == ':'].index)    \n",
        "  df = df.drop(df[df['transcription'] == ')'].index)\n",
        "  df = df.drop(df[df['transcription'] == '('].index)\n",
        "  df = df.reset_index()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    path = 'images/' + row['word'] + '.png'\n",
        "    img = Image.open(path)\n",
        "    img = resize_img(img, desired_size)\n",
        "    x = tf.convert_to_tensor(np.array(img))\n",
        "    y = tf.convert_to_tensor(Encoder.get_representation(row['transcription']))\n",
        "\n",
        "    yield(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7naHe62AGW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(Model):\n",
        "  def __init__(self):\n",
        "    super(Recognizer, self).__init__()\n",
        "    \n",
        "    # Encoder\n",
        "    self.conv1 = L.Conv2D(8, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv2 = L.Conv2D(16, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv3 = L.Conv2D(32, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv4 = L.Conv2D(64, 3, strides=1, padding='same', activation='tanh')\n",
        "    self.conv5 = L.Conv2D(128, 3, strides=1, padding='same', activation='tanh')\n",
        "\n",
        "    self.gate1 = L.Conv2D(16, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate2 = L.Conv2D(32, 3, strides=1, padding='same', activation='sigmoid')\n",
        "    self.gate3 = L.Conv2D(64, 3, strides=1, padding='same', activation='sigmoid')\n",
        "\n",
        "    # MaxPool\n",
        "    self.mp = L.MaxPool2D((32, 1))\n",
        "\n",
        "    # Decoder\n",
        "    self.gru1 = L.Bidirectional(L.GRU(256))\n",
        "    self.fc1 = L.Dense(128)\n",
        "    self.gru2 = L.Bidirectional(L.GRU(256))\n",
        "    self.fc2 = L.Dense(16)\n",
        "    self.softmax = L.Softmax(axis=1)\n",
        "    self.permute = L.Permute((3, 1, 2))\n",
        "\n",
        "  def call(self, x):\n",
        "    \n",
        "\n",
        "    # Encoder\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(x)\n",
        "\n",
        "    g1 = self.gate1(out)\n",
        "    out = out * g1\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    \n",
        "    g2 = self.gate2(out)\n",
        "    out = out * g2\n",
        "\n",
        "    out = self.conv4(out)\n",
        "\n",
        "    g3 = self.gate3(out)\n",
        "    out = out * g3\n",
        "\n",
        "    out = self.conv5(out)\n",
        "\n",
        "    print(out.shape)\n",
        "\n",
        "    # Max Pooling across vertical dimension\n",
        "    out = self.mp(out)\n",
        "\n",
        "    print(out.shape)\n",
        "\n",
        "    # Decoder\n",
        "    out = tf.reshape(out, [-1, 128, 128])\n",
        "\n",
        "    print(out.shape)\n",
        "\n",
        "    out = self.gru1(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.gru2(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.softmax(out)\n",
        "    out = self.permute(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2zKBeJSFlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_lengths(tensors):\n",
        "  lengths = []\n",
        "\n",
        "  tf.reshape(tensors, (-1, 16))\n",
        "\n",
        "  for tensor in tensors:\n",
        "    count = 0\n",
        "    for val in tensor:\n",
        "      if val != 0:\n",
        "        count += 1\n",
        "      else:\n",
        "        break\n",
        "    \n",
        "    lengths.append(count)\n",
        "\n",
        "  return lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAIwzQyJ_7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_size = images.shape[0]\n",
        "    input_lengths = tf.convert_to_tensor(np.full((batch_size,), 16))\n",
        "    label_lengths = tf.convert_to_tensor(seq_lengths(labels))\n",
        "    predictions = model(images)\n",
        "    loss = tf.nn.ctc_loss(labels, predictions, label_lengths, input_lengths)\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WjYUkAsfblo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SHAPE OF TENSOR LIKELY NEEDS TO BE IN THE SHAPE OF (BATCH, HEIGHT, WIDTH, CHANNELS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBtvnT8de0cB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1a817820-c818-464e-b6b0-c68e3242bbec"
      },
      "source": [
        "conv = L.Conv2D(8, 3, strides=1, padding='same', activation='tanh')\n",
        "conv(tf.constant(np.random.randn(1, 32, 128, 1))).shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer conv2d_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 32, 128, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0d6IYRdF4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c8543f37-270f-4c95-fb2b-67ba58829b27"
      },
      "source": [
        "t = tf.constant(np.random.randn(1, 1, 32, 128))\n",
        "model(t)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-b42af41c21fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-09b03a62d75d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_padding_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m           data_format=self._conv_op_data_format)\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# Apply causal padding to inputs for Conv1D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m   1087\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \"filter, {} != {}\".format(input_channels_dim,\n\u001b[0;32m-> 1089\u001b[0;31m                                     filter_shape[num_spatial_dims]))\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
            "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 128 != 32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmXI2FwZ9GX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5568a80c-f7e8-49e4-ede8-deed875b7446"
      },
      "source": [
        "try:\n",
        "  EPOCHS = 1\n",
        "  BATCH_SIZE = 250\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "      iam_generator,\n",
        "      (tf.int64, tf.int64),\n",
        "      (tf.TensorShape([None, None]), tf.TensorShape([None, 16]))\n",
        "  )\n",
        "\n",
        "  train_dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  model = Recognizer()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "  objective = tf.nn.ctc_loss\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for step, (images, labels) in enumerate(train_dataset):\n",
        "      train_step(images, labels)\n",
        "    \n",
        "    print('Epoch: {}, Loss: {}'.format(epoch, train_loss.result()))\n",
        "except:\n",
        "  __ITB__()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mInaccessibleTensorError\u001b[0m                   Traceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._call\u001b[0m \u001b[0;34m= <bound method Function._call of <tensorflow.python.eager.def_function.Function object at 0x7f6eeedee4a8>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32), dtype=int64, numpy=\n",
            "array([[[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [127, 190, 230, ..., 157, 226, 240],\n",
            "        [145, 205, 237, ..., 203, 239, 242],\n",
            "        [162, 219, 241, ..., 232, 239, 242]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [133, 140,  75, ..., 173, 247, 255],\n",
            "        [ 99, 203, 212, ..., 128, 248, 255],\n",
            "        [123, 239, 255, ..., 255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255, ..., 171, 236, 247],\n",
            "        [255, 255, 255, ..., 245, 246, 245],\n",
            "        [255, 255, 255, ..., 245, 246, 248]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [185,  83, 155, ..., 110, 212, 248],\n",
            "        [115, 114, 145, ..., 161, 228, 244],\n",
            "        [118, 219, 206, ..., 251, 247, 244]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [240, 233, 246, ..., 247, 244, 245],\n",
            "        [188, 232, 242, ..., 246, 245, 247],\n",
            "        [167, 177, 169, ..., 246, 244, 245]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [221, 165,  87, ..., 244, 246, 248],\n",
            "        [135, 105, 130, ..., 241, 249, 249],\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self=<tensorflow.python.eager.def_function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresults\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._stateful_fn\u001b[0m \u001b[0;34m= <tensorflow.python.eager.function.Function object at 0x7f6eecff7d30>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32), dtype=int64, numpy=\n",
            "array([[[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [127, 190, 230, ..., 157, 226, 240],\n",
            "        [145, 205, 237, ..., 203, 239, 242],\n",
            "        [162, 219, 241, ..., 232, 239, 242]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [133, 140,  75, ..., 173, 247, 255],\n",
            "        [ 99, 203, 212, ..., 128, 248, 255],\n",
            "        [123, 239, 255, ..., 255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255, ..., 171, 236, 247],\n",
            "        [255, 255, 255, ..., 245, 246, 245],\n",
            "        [255, 255, 255, ..., 245, 246, 248]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [185,  83, 155, ..., 110, 212, 248],\n",
            "        [115, 114, 145, ..., 161, 228, 244],\n",
            "        [118, 219, 206, ..., 251, 247, 244]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [240, 233, 246, ..., 247, 244, 245],\n",
            "        [188, 232, 242, ..., 246, 245, 247],\n",
            "        [167, 177, 169, ..., 246, 244, 245]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [221, 165,  87, ..., 244, 246, 248],\n",
            "        [135, 105, 130, ..., 241, 249, 249],\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<tensorflow.python.eager.function.Function object>, *args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mgraph_function\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32), dtype=int64, numpy=\n",
            "array([[[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [127, 190, 230, ..., 157, 226, 240],\n",
            "        [145, 205, 237, ..., 203, 239, 242],\n",
            "        [162, 219, 241, ..., 232, 239, 242]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [133, 140,  75, ..., 173, 247, 255],\n",
            "        [ 99, 203, 212, ..., 128, 248, 255],\n",
            "        [123, 239, 255, ..., 255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255, ..., 171, 236, 247],\n",
            "        [255, 255, 255, ..., 245, 246, 245],\n",
            "        [255, 255, 255, ..., 245, 246, 248]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [185,  83, 155, ..., 110, 212, 248],\n",
            "        [115, 114, 145, ..., 161, 228, 244],\n",
            "        [118, 219, 206, ..., 251, 247, 244]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [240, 233, 246, ..., 247, 244, 245],\n",
            "        [188, 232, 242, ..., 246, 245, 247],\n",
            "        [167, 177, 169, ..., 246, 244, 245]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [221, 165,  87, ..., 244, 246, 248],\n",
            "        [135, 105, 130, ..., 241, 249, 249],\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._maybe_define_function\u001b[0m \u001b[0;34m= <bound method Function._maybe_define_function of <tensorflow.python.eager.function.Function object at 0x7f6eecff7d30>>\u001b[0m\n",
            "\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self=<tensorflow.python.eager.function.Function object>, args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), kwargs={})\u001b[0m\n",
            "\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mgraph_function\u001b[0m \u001b[0;34m= None\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._create_graph_function\u001b[0m \u001b[0;34m= <bound method Function._create_graph_function of <tensorflow.python.eager.function.Function object at 0x7f6eecff7d30>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor: shape=(250, 128, 32), dtype=int64, numpy=\n",
            "array([[[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [127, 190, 230, ..., 157, 226, 240],\n",
            "        [145, 205, 237, ..., 203, 239, 242],\n",
            "        [162, 219, 241, ..., 232, 239, 242]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [133, 140,  75, ..., 173, 247, 255],\n",
            "        [ 99, 203, 212, ..., 128, 248, 255],\n",
            "        [123, 239, 255, ..., 255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255, ..., 171, 236, 247],\n",
            "        [255, 255, 255, ..., 245, 246, 245],\n",
            "        [255, 255, 255, ..., 245, 246, 248]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [185,  83, 155, ..., 110, 212, 248],\n",
            "        [115, 114, 145, ..., 161, 228, 244],\n",
            "        [118, 219, 206, ..., 251, 247, 244]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [240, 233, 246, ..., 247, 244, 245],\n",
            "        [188, 232, 242, ..., 246, 245, 247],\n",
            "        [167, 177, 169, ..., 246, 244, 245]],\n",
            "\n",
            "       [[255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        [255, 255, 255, ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [221, 165,  87, ..., 244, 246, 248],\n",
            "        [135, 105, 130, ..., 241, 249, 249],\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, numpy=\n",
            "array([[[ 65,   0,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 77,  79,  86, ...,   0,   0,   0]],\n",
            "\n",
            "       [[116, 111,   0, ...,   0,   0,   0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 111, 114, ...,   0,   0,   0]],\n",
            "\n",
            "       [[115, 104, 111, ...,   0,   0,   0]],\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self=<tensorflow.python.eager.function.Function object>, args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), kwargs={}, override_flat_arg_shapes=None)\u001b[0m\n",
            "\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mcapture_by_value\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._capture_by_value\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name='train_step', python_func=<function train_step>, args=(<tf.Tensor: shape=(250, 128, 32), dtype=int64, n...,\n",
            "        [226, 231, 243, ..., 223, 246, 247]]])>, <tf.Tensor: shape=(250, 1, 16), dtype=int64, num...\n",
            "\n",
            "       [[ 98, 101,   0, ...,   0,   0,   0]]])>), kwargs={}, signature=None, func_graph=<tensorflow.python.framework.func_graph.FuncGraph object>, autograph=<module 'tensorflow.python.autograph' from '/usr...es/tensorflow_core/python/autograph/__init__.py'>, autograph_options=None, add_control_dependencies=True, arg_names=['images', 'labels'], op_return_value=None, collections=None, capture_by_value=None, override_flat_arg_shapes=None)\u001b[0m\n",
            "\u001b[1;32m    976\u001b[0m                                           converted_func)\n",
            "\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mfunc_outputs\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mpython_func\u001b[0m \u001b[0;34m= <function train_step at 0x7f6eed00f1e0>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mfunc_args\u001b[0m \u001b[0;34m= (<tf.Tensor 'images:0' shape=(250, 128, 32) dtype=int64>, <tf.Tensor 'labels:0' shape=(250, 1, 16) dtype=int64>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mfunc_kwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args=(<tf.Tensor 'images:0' shape=(250, 128, 32) dtype=int64>, <tf.Tensor 'labels:0' shape=(250, 1, 16) dtype=int64>), **kwds={})\u001b[0m\n",
            "\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mweak_wrapped_fn.__wrapped__\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (<tf.Tensor 'images:0' shape=(250, 128, 32) dtype=int64>, <tf.Tensor 'labels:0' shape=(250, 1, 16) dtype=int64>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwds\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args=(<tf.Tensor 'images:0' shape=(250, 128, 32) dtype=int64>, <tf.Tensor 'labels:0' shape=(250, 1, 16) dtype=int64>), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36me.ag_error_metadata.to_exception\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36me\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mInaccessibleTensorError\u001b[0m: in converted code:\n",
            "\n",
            "    <ipython-input-52-40872588ad77>:6 train_step  *\n",
            "        label_lengths = tf.convert_to_tensor(seq_lengths(labels))\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1256 convert_to_tensor_v2\n",
            "        as_ref=False)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1314 convert_to_tensor\n",
            "        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1368 _autopacking_conversion_function\n",
            "        return _autopacking_helper(v, dtype, name or \"packed\")\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1304 _autopacking_helper\n",
            "        return gen_array_ops.pack(elems_as_tensors, name=scope)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py:5704 pack\n",
            "        \"Pack\", values=values, axis=axis, name=name)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n",
            "        attrs=attr_protos, op_def=op_def)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:591 _create_op_internal\n",
            "        inp = self.capture(inp)\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:641 capture\n",
            "        % (tensor, tensor.graph, self))\n",
            "\n",
            "    InaccessibleTensorError: The tensor 'Tensor(\"while:4\", shape=(), dtype=int32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_37116, id=140114362707248); accessed from: FuncGraph(name=train_step, id=140114371754304).\n",
            "    \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZLQgNk4Td_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = tf.convert_to_tensor(tf.constant([[1, 2, 3]]))\n",
        "tf.reshape(t, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSA1f8pLq6D",
        "colab_type": "code",
        "outputId": "91dcf26c-c98a-42e6-90b4-4b22762607e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataset = dataset.batch(BATCH_SIZE)\n",
        "for step, (x, y) in enumerate(train_dataset):\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 128, 32)\n",
            "(1, 1, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}